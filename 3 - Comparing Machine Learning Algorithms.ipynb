{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Comparing Machine Learning Algorithms\n",
    "\n",
    "Welcome to the third part of the practical session of the Workshop __Machine Learning for Optical Network Systems!__ In this exercise you will:\n",
    "\n",
    " - Build multiple models to use in the same use-case as exercise 2 using various algorithms.\n",
    " - Learn how to compare these models against each other to make you select an appropriate selection.\n",
    " \n",
    "__Let's go!__\n",
    "\n",
    "Similar to exercise 2, this part of the practical session is based on the papers:\n",
    "- Active Wavelength Load as a Feature for QoT Estimation Based on Support Vector Machine\n",
    "- A Performance Analysis of Supervised Learning Classifiers for QoT Estimation in ROADM-based Networks\n",
    "\n",
    "## Getting started\n",
    "\n",
    "Please refer to the publications for detailed explanations on the use cases. Go to File -> Open -> and click on the directory publications/ and files diaz2019active.pdf and diaz2019performance.pdf.\n",
    "\n",
    "### 1 - Import the required libraries\n",
    "\n",
    "As in the previous exercises, execute the cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_reader as fr\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load the dataset\n",
    "\n",
    "Now, get the data from the files below (given to you), and use a scaler to transform your data so it can be easily used by all the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_file = 'dataset/balanced-20372.csv'\n",
    "testing_set_file = 'dataset/testset-2351.csv'\n",
    "\n",
    "# Retrieve and format data for training set\n",
    "X_train, y_train = fr.FileReader.read_array_three_class(fr.FileReader(), training_set_file)\n",
    "\n",
    "# Retrieve and format data for testing set\n",
    "X_test, y_test = fr.FileReader.read_array_three_class(fr.FileReader(), testing_set_file)\n",
    "\n",
    "# Use a StandardScaler to scale your dataset.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# apply the transformations to the data:\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Declaring parameters\n",
    "\n",
    "The cell below may seem like a lot of code, but you are simply generating lists with names and parameters to be used by your multiple algorithms. __Don't forget to execute it though!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"RBF SVM\", \"Linear SVM\",\n",
    "         \"Logistic Regression\",\"Decision Tree\", \"Neural Network\",\n",
    "         \"Naive Bayes\", \"LDA\"]\n",
    "   \n",
    "ensemble_names = [\"Random Forest\", \"AdaBoost\", \"Bagging\"]\n",
    "\n",
    "parameters = {\n",
    "    \"Nearest Neighbors\": {'n_neighbors': [1]},\n",
    "    \"RBF SVM\": {'kernel':['rbf'], 'gamma':[100], 'C':[0.0001]},\n",
    "    \"Linear SVM\": {'kernel':['linear'], 'gamma':[100], 'C':[0.0001]},\n",
    "    \"Logistic Regression\":{'solver':['lbfgs'], 'multi_class':['multinomial'], 'random_state':[1]}, \n",
    "    \"Decision Tree\": {'max_depth':[5]},\n",
    "    \"Neural Network\": {'alpha':[1], 'max_iter':[10000]},\n",
    "    \"Naive Bayes\": {},\n",
    "    \"LDA\": {'n_components':[None], 'priors':[None], 'shrinkage':['auto'],\n",
    "              'solver':['lsqr']}         \n",
    "    }\n",
    "\n",
    "ensemble_parameters = {\n",
    "    \"Random Forest\": {'max_depth':[5], 'n_estimators':[10], 'max_features':[1]},\n",
    "    \"AdaBoost\": {'n_estimators':[10]}, \n",
    "    \"Bagging\":{'n_estimators':[100],'max_samples':[0.8], 'max_features':[0.8]}\n",
    "    }\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    SVC(),\n",
    "    SVC(),\n",
    "    LogisticRegression(), \n",
    "    DecisionTreeClassifier(),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis()\n",
    "    ]\n",
    "    \n",
    "ensemble_classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    BaggingClassifier()\n",
    "    ]\n",
    "\n",
    "y_train2 = np.argmax(y_train, axis=1)\n",
    "y_test2 = np.argmax(y_test, axis=1)\n",
    "\n",
    "y2_clfs = [\"Linear SVM\", \"RBF SVM\", \"Logistic Regression\", \"Decision Tree\", \"AdaBoost\", \"Naive Bayes\", \"LDA\", \"Bagging\"]\n",
    "\n",
    "classifier_stats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Fitting data into the models and evaluate\n",
    "\n",
    "Create a for loop to iterate through the implementation of the multiple Machine Learning algorithms and check the accuracy of each. This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(\"Running execution for classifier: %s\" %name )\n",
    "    # use the GridSearchCV for n_jobs and cv instantiation\n",
    "    clf_grid = GridSearchCV(clf, parameters[name], n_jobs=10, cv=5)\n",
    "    # check y variables modification\n",
    "    if name in y2_clfs:\n",
    "        ts = time.time()\n",
    "        clf_grid.fit(X_train, y_train2)\n",
    "        new_ts = time.time()\n",
    "        total_time = new_ts - ts\n",
    "        score = clf_grid.score(X_test, y_test2) # compute average accuracy\n",
    "        y_pred = clf_grid.predict(X_test) # predict X_test based on trained model\n",
    "        f1_score = metrics.f1_score(y_test2, y_pred, average='micro')\n",
    "    else:\n",
    "        ts = time.time()\n",
    "        clf_grid.fit(X_train, y_train)\n",
    "        new_ts = time.time()\n",
    "        total_time = new_ts - ts\n",
    "        score = clf_grid.score(X_test, y_test)\n",
    "        y_pred = clf_grid.predict(X_test) # predict X_test based on trained model\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    # save results on classifier statistics object\n",
    "    classifier_stats[name] = (score, f1_score, total_time)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "for clfs in classifier_stats:\n",
    "    (score, f1_score, total_time) = classifier_stats[clfs]\n",
    "    print(\"Classifier: %s.\\nF1-score: %s.\\nExecution time: %s seconds.\" %(clfs, f1_score, total_time))\n",
    "    print(\"% - % - % - % - % - % - % - % - % - % - % - %\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Congratulations!__\n",
    "\n",
    "Now you know the basic tools through the Scikit-learn framework to execute Machine Learning algorithms plain and easy! Feel free to go back to the previous cell to also check the performance of the ensemble classifiers and/or change the hyperparameters of the algorithms to verify what works best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
